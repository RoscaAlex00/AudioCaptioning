adapt:
  audio_emb_size: 128
  nb_layers: 1
data:
  root_dir: data
  features_dir: clotho_v2_vggish
  input_field_name: vggish_embeddings
  output_field_name: caption
  cond_tok_class_sel: sample
  cond_tok_field_name:
  cond_tok_separator: '. '
  cond_tok_time_sel: unroll
  max_audio_len: 32
  max_caption_tok_len: 64
lm:
  config: # Model parameters
    activation_dropout: 0.1
    activation_function: 'gelu'
    attention_dropout: 0.1
    classifier_dropout: 0.0
    d_model: 768
    decoder_attention_heads: 12
    decoder_ffn_dim: 3072
    decoder_layers: 6
    dropout: 0.1
    encoder_attention_heads: 12
    encoder_ffn_dim: 3072
    encoder_layers: 6
    vocab_size: 50265
    token_conditioning: false
    metadata: false
  generation: # Generation parameters
    early_stopping: true
    no_repeat_ngram_size: 3
    num_beams: 4
    min_length: 5
    max_length: 100
    length_penalty: 1.0
    decoding: beam
  eval_model: best
  eval_checkpoint: 0
  freeze:
    all: false
    attn: false
    dec: false
    dec_attn: false
    dec_mlp: false
    dec_self_attn: false
    enc: false
    enc_attn: false
    enc_mlp: false
    mlp: false
  tokenizer: facebook/bart-base
  pretrained: null
training:
  eval_steps: 600
  force_cpu: false
  batch_size: 16
  gradient_accumulation_steps: 2
  num_workers: 4
  lr: 1.0e-05
  nb_epochs: 15
  save_steps: 600
  seed: 0
workflow:
  train: true
  validate: true
  evaluate: true
  infer: true
